{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "# Device cinfiguration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameter \n",
    "num_epochs =4\n",
    "batch_size =4\n",
    "learning_rate =0.001\n",
    "\n",
    "# Dataset has PILImages of range [0,1]\n",
    "# We transform then to Tensors of normalized range [-1,1] \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle=True)   \n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')\n",
    "classes_map = {'0':'plane',\n",
    "                '1':'car',\n",
    "                '2':'bird',\n",
    "                '3':'cat',\n",
    "                '4':'deer',\n",
    "                '5':'dog',\n",
    "                '6':'frog',\n",
    "                '7':'horse',\n",
    "                '8':'ship',\n",
    "                '9':'truck',\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "sample,labels = examples.next()\n",
    "print(sample.shape, labels.shape)\n",
    "                                    \n",
    "for i in range(4): \n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(sample[i][0],cmap='gray')\n",
    "    plt.title(str(labels[i].item()),c='r')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4, step 100/12500, loss = 2.2629\n",
      "epoch 1/4, step 200/12500, loss = 2.2868\n",
      "epoch 1/4, step 300/12500, loss = 2.3022\n",
      "epoch 1/4, step 400/12500, loss = 2.3382\n",
      "epoch 1/4, step 500/12500, loss = 2.2441\n",
      "epoch 1/4, step 600/12500, loss = 2.2944\n",
      "epoch 1/4, step 700/12500, loss = 2.3388\n",
      "epoch 1/4, step 800/12500, loss = 2.2607\n",
      "epoch 1/4, step 900/12500, loss = 2.3061\n",
      "epoch 1/4, step 1000/12500, loss = 2.3242\n",
      "epoch 1/4, step 1100/12500, loss = 2.3517\n",
      "epoch 1/4, step 1200/12500, loss = 2.3119\n",
      "epoch 1/4, step 1300/12500, loss = 2.3622\n",
      "epoch 1/4, step 1400/12500, loss = 2.2981\n",
      "epoch 1/4, step 1500/12500, loss = 2.3077\n",
      "epoch 1/4, step 1600/12500, loss = 2.3432\n",
      "epoch 1/4, step 1700/12500, loss = 2.3044\n",
      "epoch 1/4, step 1800/12500, loss = 2.2759\n",
      "epoch 1/4, step 1900/12500, loss = 2.3029\n",
      "epoch 1/4, step 2000/12500, loss = 2.2920\n",
      "epoch 1/4, step 2100/12500, loss = 2.3086\n",
      "epoch 1/4, step 2200/12500, loss = 2.2665\n",
      "epoch 1/4, step 2300/12500, loss = 2.3247\n",
      "epoch 1/4, step 2400/12500, loss = 2.2919\n",
      "epoch 1/4, step 2500/12500, loss = 2.3397\n",
      "epoch 1/4, step 2600/12500, loss = 2.2849\n",
      "epoch 1/4, step 2700/12500, loss = 2.3284\n",
      "epoch 1/4, step 2800/12500, loss = 2.2825\n",
      "epoch 1/4, step 2900/12500, loss = 2.2917\n",
      "epoch 1/4, step 3000/12500, loss = 2.2707\n",
      "epoch 1/4, step 3100/12500, loss = 2.2938\n",
      "epoch 1/4, step 3200/12500, loss = 2.2574\n",
      "epoch 1/4, step 3300/12500, loss = 2.2965\n",
      "epoch 1/4, step 3400/12500, loss = 2.2852\n",
      "epoch 1/4, step 3500/12500, loss = 2.2829\n",
      "epoch 1/4, step 3600/12500, loss = 2.2660\n",
      "epoch 1/4, step 3700/12500, loss = 2.2969\n",
      "epoch 1/4, step 3800/12500, loss = 2.3006\n",
      "epoch 1/4, step 3900/12500, loss = 2.3490\n",
      "epoch 1/4, step 4000/12500, loss = 2.3132\n",
      "epoch 1/4, step 4100/12500, loss = 2.3079\n",
      "epoch 1/4, step 4200/12500, loss = 2.2897\n",
      "epoch 1/4, step 4300/12500, loss = 2.2793\n",
      "epoch 1/4, step 4400/12500, loss = 2.2814\n",
      "epoch 1/4, step 4500/12500, loss = 2.3149\n",
      "epoch 1/4, step 4600/12500, loss = 2.2948\n",
      "epoch 1/4, step 4700/12500, loss = 2.3141\n",
      "epoch 1/4, step 4800/12500, loss = 2.2706\n",
      "epoch 1/4, step 4900/12500, loss = 2.2747\n",
      "epoch 1/4, step 5000/12500, loss = 2.2873\n",
      "epoch 1/4, step 5100/12500, loss = 2.3070\n",
      "epoch 1/4, step 5200/12500, loss = 2.2991\n",
      "epoch 1/4, step 5300/12500, loss = 2.3277\n",
      "epoch 1/4, step 5400/12500, loss = 2.3003\n",
      "epoch 1/4, step 5500/12500, loss = 2.2756\n",
      "epoch 1/4, step 5600/12500, loss = 2.3098\n",
      "epoch 1/4, step 5700/12500, loss = 2.2975\n",
      "epoch 1/4, step 5800/12500, loss = 2.2922\n",
      "epoch 1/4, step 5900/12500, loss = 2.2977\n",
      "epoch 1/4, step 6000/12500, loss = 2.2929\n",
      "epoch 1/4, step 6100/12500, loss = 2.3018\n",
      "epoch 1/4, step 6200/12500, loss = 2.2735\n",
      "epoch 1/4, step 6300/12500, loss = 2.2879\n",
      "epoch 1/4, step 6400/12500, loss = 2.2881\n",
      "epoch 1/4, step 6500/12500, loss = 2.3295\n",
      "epoch 1/4, step 6600/12500, loss = 2.3196\n",
      "epoch 1/4, step 6700/12500, loss = 2.2890\n",
      "epoch 1/4, step 6800/12500, loss = 2.2882\n",
      "epoch 1/4, step 6900/12500, loss = 2.3002\n",
      "epoch 1/4, step 7000/12500, loss = 2.2747\n",
      "epoch 1/4, step 7100/12500, loss = 2.3213\n",
      "epoch 1/4, step 7200/12500, loss = 2.2789\n",
      "epoch 1/4, step 7300/12500, loss = 2.2923\n",
      "epoch 1/4, step 7400/12500, loss = 2.2766\n",
      "epoch 1/4, step 7500/12500, loss = 2.2842\n",
      "epoch 1/4, step 7600/12500, loss = 2.2735\n",
      "epoch 1/4, step 7700/12500, loss = 2.2994\n",
      "epoch 1/4, step 7800/12500, loss = 2.2842\n",
      "epoch 1/4, step 7900/12500, loss = 2.3010\n",
      "epoch 1/4, step 8000/12500, loss = 2.2525\n",
      "epoch 1/4, step 8100/12500, loss = 2.2841\n",
      "epoch 1/4, step 8200/12500, loss = 2.2864\n",
      "epoch 1/4, step 8300/12500, loss = 2.2356\n",
      "epoch 1/4, step 8400/12500, loss = 2.2940\n",
      "epoch 1/4, step 8500/12500, loss = 2.2679\n",
      "epoch 1/4, step 8600/12500, loss = 2.3058\n",
      "epoch 1/4, step 8700/12500, loss = 2.2415\n",
      "epoch 1/4, step 8800/12500, loss = 2.2556\n",
      "epoch 1/4, step 8900/12500, loss = 2.2539\n",
      "epoch 1/4, step 9000/12500, loss = 2.2600\n",
      "epoch 1/4, step 9100/12500, loss = 2.2684\n",
      "epoch 1/4, step 9200/12500, loss = 2.2774\n",
      "epoch 1/4, step 9300/12500, loss = 2.1829\n",
      "epoch 1/4, step 9400/12500, loss = 2.1896\n",
      "epoch 1/4, step 9500/12500, loss = 2.2768\n",
      "epoch 1/4, step 9600/12500, loss = 2.1940\n",
      "epoch 1/4, step 9700/12500, loss = 2.2103\n",
      "epoch 1/4, step 9800/12500, loss = 2.3009\n",
      "epoch 1/4, step 9900/12500, loss = 2.2451\n",
      "epoch 1/4, step 10000/12500, loss = 2.3972\n",
      "epoch 1/4, step 10100/12500, loss = 2.2774\n",
      "epoch 1/4, step 10200/12500, loss = 2.1812\n",
      "epoch 1/4, step 10300/12500, loss = 2.2675\n",
      "epoch 1/4, step 10400/12500, loss = 2.0868\n",
      "epoch 1/4, step 10500/12500, loss = 2.2933\n",
      "epoch 1/4, step 10600/12500, loss = 2.2388\n",
      "epoch 1/4, step 10700/12500, loss = 2.2665\n",
      "epoch 1/4, step 10800/12500, loss = 2.2440\n",
      "epoch 1/4, step 10900/12500, loss = 2.3278\n",
      "epoch 1/4, step 11000/12500, loss = 2.2666\n",
      "epoch 1/4, step 11100/12500, loss = 1.9407\n",
      "epoch 1/4, step 11200/12500, loss = 2.0013\n",
      "epoch 1/4, step 11300/12500, loss = 1.9522\n",
      "epoch 1/4, step 11400/12500, loss = 2.1899\n",
      "epoch 1/4, step 11500/12500, loss = 2.2260\n",
      "epoch 1/4, step 11600/12500, loss = 2.1041\n",
      "epoch 1/4, step 11700/12500, loss = 2.2350\n",
      "epoch 1/4, step 11800/12500, loss = 2.2745\n",
      "epoch 1/4, step 11900/12500, loss = 1.8816\n",
      "epoch 1/4, step 12000/12500, loss = 1.8277\n",
      "epoch 1/4, step 12100/12500, loss = 2.0780\n",
      "epoch 1/4, step 12200/12500, loss = 2.2482\n",
      "epoch 1/4, step 12300/12500, loss = 2.1562\n",
      "epoch 1/4, step 12400/12500, loss = 2.2819\n",
      "epoch 1/4, step 12500/12500, loss = 2.2592\n",
      "epoch 2/4, step 100/12500, loss = 2.0051\n",
      "epoch 2/4, step 200/12500, loss = 2.2218\n",
      "epoch 2/4, step 300/12500, loss = 2.0534\n",
      "epoch 2/4, step 400/12500, loss = 2.2973\n",
      "epoch 2/4, step 500/12500, loss = 2.0380\n",
      "epoch 2/4, step 600/12500, loss = 2.4514\n",
      "epoch 2/4, step 700/12500, loss = 2.1879\n",
      "epoch 2/4, step 800/12500, loss = 2.1649\n",
      "epoch 2/4, step 900/12500, loss = 2.1372\n",
      "epoch 2/4, step 1000/12500, loss = 2.1130\n",
      "epoch 2/4, step 1100/12500, loss = 2.0077\n",
      "epoch 2/4, step 1200/12500, loss = 1.7662\n",
      "epoch 2/4, step 1300/12500, loss = 1.9549\n",
      "epoch 2/4, step 1400/12500, loss = 2.3035\n",
      "epoch 2/4, step 1500/12500, loss = 2.4771\n",
      "epoch 2/4, step 1600/12500, loss = 2.0817\n",
      "epoch 2/4, step 1700/12500, loss = 2.0701\n",
      "epoch 2/4, step 1800/12500, loss = 2.1093\n",
      "epoch 2/4, step 1900/12500, loss = 2.0610\n",
      "epoch 2/4, step 2000/12500, loss = 2.3783\n",
      "epoch 2/4, step 2100/12500, loss = 1.8991\n",
      "epoch 2/4, step 2200/12500, loss = 2.1699\n",
      "epoch 2/4, step 2300/12500, loss = 1.6898\n",
      "epoch 2/4, step 2400/12500, loss = 2.0575\n",
      "epoch 2/4, step 2500/12500, loss = 1.7402\n",
      "epoch 2/4, step 2600/12500, loss = 2.0842\n",
      "epoch 2/4, step 2700/12500, loss = 1.8609\n",
      "epoch 2/4, step 2800/12500, loss = 2.1170\n",
      "epoch 2/4, step 2900/12500, loss = 1.8582\n",
      "epoch 2/4, step 3000/12500, loss = 1.8889\n",
      "epoch 2/4, step 3100/12500, loss = 1.7636\n",
      "epoch 2/4, step 3200/12500, loss = 1.9699\n",
      "epoch 2/4, step 3300/12500, loss = 2.2881\n",
      "epoch 2/4, step 3400/12500, loss = 1.6494\n",
      "epoch 2/4, step 3500/12500, loss = 2.1052\n",
      "epoch 2/4, step 3600/12500, loss = 2.3434\n",
      "epoch 2/4, step 3700/12500, loss = 1.8588\n",
      "epoch 2/4, step 3800/12500, loss = 1.9901\n",
      "epoch 2/4, step 3900/12500, loss = 2.1936\n",
      "epoch 2/4, step 4000/12500, loss = 2.1534\n",
      "epoch 2/4, step 4100/12500, loss = 2.0318\n",
      "epoch 2/4, step 4200/12500, loss = 2.3712\n",
      "epoch 2/4, step 4300/12500, loss = 1.7716\n",
      "epoch 2/4, step 4400/12500, loss = 1.6724\n",
      "epoch 2/4, step 4500/12500, loss = 1.8102\n",
      "epoch 2/4, step 4600/12500, loss = 2.5186\n",
      "epoch 2/4, step 4700/12500, loss = 1.5604\n",
      "epoch 2/4, step 4800/12500, loss = 1.8235\n",
      "epoch 2/4, step 4900/12500, loss = 1.9762\n",
      "epoch 2/4, step 5000/12500, loss = 2.3561\n",
      "epoch 2/4, step 5100/12500, loss = 3.0018\n",
      "epoch 2/4, step 5200/12500, loss = 1.5247\n",
      "epoch 2/4, step 5300/12500, loss = 2.2107\n",
      "epoch 2/4, step 5400/12500, loss = 1.7299\n",
      "epoch 2/4, step 5500/12500, loss = 1.6587\n",
      "epoch 2/4, step 5600/12500, loss = 2.2768\n",
      "epoch 2/4, step 5700/12500, loss = 1.7960\n",
      "epoch 2/4, step 5800/12500, loss = 2.2264\n",
      "epoch 2/4, step 5900/12500, loss = 2.1790\n",
      "epoch 2/4, step 6000/12500, loss = 2.1814\n",
      "epoch 2/4, step 6100/12500, loss = 1.7343\n",
      "epoch 2/4, step 6200/12500, loss = 2.0450\n",
      "epoch 2/4, step 6300/12500, loss = 1.6042\n",
      "epoch 2/4, step 6400/12500, loss = 2.1673\n",
      "epoch 2/4, step 6500/12500, loss = 2.0213\n",
      "epoch 2/4, step 6600/12500, loss = 1.7949\n",
      "epoch 2/4, step 6700/12500, loss = 1.3151\n",
      "epoch 2/4, step 6800/12500, loss = 2.1947\n",
      "epoch 2/4, step 6900/12500, loss = 1.9872\n",
      "epoch 2/4, step 7000/12500, loss = 1.3872\n",
      "epoch 2/4, step 7100/12500, loss = 2.2049\n",
      "epoch 2/4, step 7200/12500, loss = 2.4655\n",
      "epoch 2/4, step 7300/12500, loss = 1.5088\n",
      "epoch 2/4, step 7400/12500, loss = 1.8955\n",
      "epoch 2/4, step 7500/12500, loss = 1.3233\n",
      "epoch 2/4, step 7600/12500, loss = 1.6953\n",
      "epoch 2/4, step 7700/12500, loss = 1.9265\n",
      "epoch 2/4, step 7800/12500, loss = 1.8513\n",
      "epoch 2/4, step 7900/12500, loss = 1.6461\n",
      "epoch 2/4, step 8000/12500, loss = 1.5095\n",
      "epoch 2/4, step 8100/12500, loss = 1.7700\n",
      "epoch 2/4, step 8200/12500, loss = 2.2468\n",
      "epoch 2/4, step 8300/12500, loss = 1.2284\n",
      "epoch 2/4, step 8400/12500, loss = 1.1779\n",
      "epoch 2/4, step 8500/12500, loss = 2.3022\n",
      "epoch 2/4, step 8600/12500, loss = 2.8399\n",
      "epoch 2/4, step 8700/12500, loss = 1.3320\n",
      "epoch 2/4, step 8800/12500, loss = 2.1368\n",
      "epoch 2/4, step 8900/12500, loss = 1.5714\n",
      "epoch 2/4, step 9000/12500, loss = 2.2213\n",
      "epoch 2/4, step 9100/12500, loss = 1.7194\n",
      "epoch 2/4, step 9200/12500, loss = 2.2615\n",
      "epoch 2/4, step 9300/12500, loss = 1.5137\n",
      "epoch 2/4, step 9400/12500, loss = 1.9756\n",
      "epoch 2/4, step 9500/12500, loss = 1.4926\n",
      "epoch 2/4, step 9600/12500, loss = 2.3806\n",
      "epoch 2/4, step 9700/12500, loss = 2.4544\n",
      "epoch 2/4, step 9800/12500, loss = 2.0191\n",
      "epoch 2/4, step 9900/12500, loss = 1.7910\n",
      "epoch 2/4, step 10000/12500, loss = 1.9590\n",
      "epoch 2/4, step 10100/12500, loss = 1.3607\n",
      "epoch 2/4, step 10200/12500, loss = 2.8093\n",
      "epoch 2/4, step 10300/12500, loss = 1.8158\n",
      "epoch 2/4, step 10400/12500, loss = 1.8222\n",
      "epoch 2/4, step 10500/12500, loss = 2.4254\n",
      "epoch 2/4, step 10600/12500, loss = 1.1298\n",
      "epoch 2/4, step 10700/12500, loss = 2.3387\n",
      "epoch 2/4, step 10800/12500, loss = 1.6467\n",
      "epoch 2/4, step 10900/12500, loss = 2.1774\n",
      "epoch 2/4, step 11000/12500, loss = 1.8364\n",
      "epoch 2/4, step 11100/12500, loss = 1.6867\n",
      "epoch 2/4, step 11200/12500, loss = 2.6033\n",
      "epoch 2/4, step 11300/12500, loss = 1.9888\n",
      "epoch 2/4, step 11400/12500, loss = 1.6258\n",
      "epoch 2/4, step 11500/12500, loss = 1.7684\n",
      "epoch 2/4, step 11600/12500, loss = 1.1959\n",
      "epoch 2/4, step 11700/12500, loss = 1.2499\n",
      "epoch 2/4, step 11800/12500, loss = 1.8891\n",
      "epoch 2/4, step 11900/12500, loss = 2.2608\n",
      "epoch 2/4, step 12000/12500, loss = 2.1932\n",
      "epoch 2/4, step 12100/12500, loss = 1.3621\n",
      "epoch 2/4, step 12200/12500, loss = 2.6377\n",
      "epoch 2/4, step 12300/12500, loss = 0.9532\n",
      "epoch 2/4, step 12400/12500, loss = 1.7238\n",
      "epoch 2/4, step 12500/12500, loss = 1.4363\n",
      "epoch 3/4, step 100/12500, loss = 1.1034\n",
      "epoch 3/4, step 200/12500, loss = 1.4568\n",
      "epoch 3/4, step 300/12500, loss = 1.9664\n",
      "epoch 3/4, step 400/12500, loss = 2.3486\n",
      "epoch 3/4, step 500/12500, loss = 2.3029\n",
      "epoch 3/4, step 600/12500, loss = 1.1784\n",
      "epoch 3/4, step 700/12500, loss = 1.8865\n",
      "epoch 3/4, step 800/12500, loss = 1.3165\n",
      "epoch 3/4, step 900/12500, loss = 1.1765\n",
      "epoch 3/4, step 1000/12500, loss = 1.1112\n",
      "epoch 3/4, step 1100/12500, loss = 2.2649\n",
      "epoch 3/4, step 1200/12500, loss = 1.4990\n",
      "epoch 3/4, step 1300/12500, loss = 1.1533\n",
      "epoch 3/4, step 1400/12500, loss = 1.8329\n",
      "epoch 3/4, step 1500/12500, loss = 2.5562\n",
      "epoch 3/4, step 1600/12500, loss = 2.0300\n",
      "epoch 3/4, step 1700/12500, loss = 1.3308\n",
      "epoch 3/4, step 1800/12500, loss = 1.6481\n",
      "epoch 3/4, step 1900/12500, loss = 1.4845\n",
      "epoch 3/4, step 2000/12500, loss = 1.7408\n",
      "epoch 3/4, step 2100/12500, loss = 2.2251\n",
      "epoch 3/4, step 2200/12500, loss = 1.5224\n",
      "epoch 3/4, step 2300/12500, loss = 1.5298\n",
      "epoch 3/4, step 2400/12500, loss = 1.8358\n",
      "epoch 3/4, step 2500/12500, loss = 1.5355\n",
      "epoch 3/4, step 2600/12500, loss = 1.7497\n",
      "epoch 3/4, step 2700/12500, loss = 1.9167\n",
      "epoch 3/4, step 2800/12500, loss = 1.7285\n",
      "epoch 3/4, step 2900/12500, loss = 1.8702\n",
      "epoch 3/4, step 3000/12500, loss = 1.2177\n",
      "epoch 3/4, step 3100/12500, loss = 1.4164\n",
      "epoch 3/4, step 3200/12500, loss = 1.1880\n",
      "epoch 3/4, step 3300/12500, loss = 1.7150\n",
      "epoch 3/4, step 3400/12500, loss = 1.2264\n",
      "epoch 3/4, step 3500/12500, loss = 1.6140\n",
      "epoch 3/4, step 3600/12500, loss = 2.0435\n",
      "epoch 3/4, step 3700/12500, loss = 1.5653\n",
      "epoch 3/4, step 3800/12500, loss = 2.0587\n",
      "epoch 3/4, step 3900/12500, loss = 2.0679\n",
      "epoch 3/4, step 4000/12500, loss = 2.3642\n",
      "epoch 3/4, step 4100/12500, loss = 1.6340\n",
      "epoch 3/4, step 4200/12500, loss = 0.6902\n",
      "epoch 3/4, step 4300/12500, loss = 1.1670\n",
      "epoch 3/4, step 4400/12500, loss = 1.0109\n",
      "epoch 3/4, step 4500/12500, loss = 0.8651\n",
      "epoch 3/4, step 4600/12500, loss = 1.4963\n",
      "epoch 3/4, step 4700/12500, loss = 0.9560\n",
      "epoch 3/4, step 4800/12500, loss = 1.2177\n",
      "epoch 3/4, step 4900/12500, loss = 1.9943\n",
      "epoch 3/4, step 5000/12500, loss = 1.5524\n",
      "epoch 3/4, step 5100/12500, loss = 1.7809\n",
      "epoch 3/4, step 5200/12500, loss = 2.5114\n",
      "epoch 3/4, step 5300/12500, loss = 1.7395\n",
      "epoch 3/4, step 5400/12500, loss = 1.6530\n",
      "epoch 3/4, step 5500/12500, loss = 1.4098\n",
      "epoch 3/4, step 5600/12500, loss = 1.6039\n",
      "epoch 3/4, step 5700/12500, loss = 2.0007\n",
      "epoch 3/4, step 5800/12500, loss = 1.6379\n",
      "epoch 3/4, step 5900/12500, loss = 2.5918\n",
      "epoch 3/4, step 6000/12500, loss = 1.7335\n",
      "epoch 3/4, step 6100/12500, loss = 1.6540\n",
      "epoch 3/4, step 6200/12500, loss = 1.9738\n",
      "epoch 3/4, step 6300/12500, loss = 1.3587\n",
      "epoch 3/4, step 6400/12500, loss = 1.4333\n",
      "epoch 3/4, step 6500/12500, loss = 1.2794\n",
      "epoch 3/4, step 6600/12500, loss = 2.4667\n",
      "epoch 3/4, step 6700/12500, loss = 1.3467\n",
      "epoch 3/4, step 6800/12500, loss = 1.5031\n",
      "epoch 3/4, step 6900/12500, loss = 2.2518\n",
      "epoch 3/4, step 7000/12500, loss = 1.3815\n",
      "epoch 3/4, step 7100/12500, loss = 1.1505\n",
      "epoch 3/4, step 7200/12500, loss = 1.6547\n",
      "epoch 3/4, step 7300/12500, loss = 2.0325\n",
      "epoch 3/4, step 7400/12500, loss = 1.8226\n",
      "epoch 3/4, step 7500/12500, loss = 1.6345\n",
      "epoch 3/4, step 7600/12500, loss = 1.2888\n",
      "epoch 3/4, step 7700/12500, loss = 1.7548\n",
      "epoch 3/4, step 7800/12500, loss = 1.4537\n",
      "epoch 3/4, step 7900/12500, loss = 1.5426\n",
      "epoch 3/4, step 8000/12500, loss = 1.6640\n",
      "epoch 3/4, step 8100/12500, loss = 1.9355\n",
      "epoch 3/4, step 8200/12500, loss = 1.0876\n",
      "epoch 3/4, step 8300/12500, loss = 0.9115\n",
      "epoch 3/4, step 8400/12500, loss = 1.5930\n",
      "epoch 3/4, step 8500/12500, loss = 1.2770\n",
      "epoch 3/4, step 8600/12500, loss = 1.5627\n",
      "epoch 3/4, step 8700/12500, loss = 1.4327\n",
      "epoch 3/4, step 8800/12500, loss = 1.3056\n",
      "epoch 3/4, step 8900/12500, loss = 1.8585\n",
      "epoch 3/4, step 9000/12500, loss = 1.1051\n",
      "epoch 3/4, step 9100/12500, loss = 1.9759\n",
      "epoch 3/4, step 9200/12500, loss = 1.2944\n",
      "epoch 3/4, step 9300/12500, loss = 1.7625\n",
      "epoch 3/4, step 9400/12500, loss = 1.8500\n",
      "epoch 3/4, step 9500/12500, loss = 1.2438\n",
      "epoch 3/4, step 9600/12500, loss = 1.5349\n",
      "epoch 3/4, step 9700/12500, loss = 1.6976\n",
      "epoch 3/4, step 9800/12500, loss = 0.9959\n",
      "epoch 3/4, step 9900/12500, loss = 1.4420\n",
      "epoch 3/4, step 10000/12500, loss = 1.0948\n",
      "epoch 3/4, step 10100/12500, loss = 1.4442\n",
      "epoch 3/4, step 10200/12500, loss = 1.8945\n",
      "epoch 3/4, step 10300/12500, loss = 2.0727\n",
      "epoch 3/4, step 10400/12500, loss = 1.6724\n",
      "epoch 3/4, step 10500/12500, loss = 0.6724\n",
      "epoch 3/4, step 10600/12500, loss = 2.6806\n",
      "epoch 3/4, step 10700/12500, loss = 1.3083\n",
      "epoch 3/4, step 10800/12500, loss = 1.3082\n",
      "epoch 3/4, step 10900/12500, loss = 1.2657\n",
      "epoch 3/4, step 11000/12500, loss = 1.7221\n",
      "epoch 3/4, step 11100/12500, loss = 1.9948\n",
      "epoch 3/4, step 11200/12500, loss = 1.5506\n",
      "epoch 3/4, step 11300/12500, loss = 1.3350\n",
      "epoch 3/4, step 11400/12500, loss = 3.5175\n",
      "epoch 3/4, step 11500/12500, loss = 1.3243\n",
      "epoch 3/4, step 11600/12500, loss = 1.0986\n",
      "epoch 3/4, step 11700/12500, loss = 1.9572\n",
      "epoch 3/4, step 11800/12500, loss = 2.6706\n",
      "epoch 3/4, step 11900/12500, loss = 1.1090\n",
      "epoch 3/4, step 12000/12500, loss = 1.0498\n",
      "epoch 3/4, step 12100/12500, loss = 1.0868\n",
      "epoch 3/4, step 12200/12500, loss = 1.7799\n",
      "epoch 3/4, step 12300/12500, loss = 2.9214\n",
      "epoch 3/4, step 12400/12500, loss = 1.8977\n",
      "epoch 3/4, step 12500/12500, loss = 2.5096\n",
      "epoch 4/4, step 100/12500, loss = 2.2947\n",
      "epoch 4/4, step 200/12500, loss = 1.4006\n",
      "epoch 4/4, step 300/12500, loss = 1.5352\n",
      "epoch 4/4, step 400/12500, loss = 1.4802\n",
      "epoch 4/4, step 500/12500, loss = 1.4049\n",
      "epoch 4/4, step 600/12500, loss = 1.6021\n",
      "epoch 4/4, step 700/12500, loss = 1.4048\n",
      "epoch 4/4, step 800/12500, loss = 1.3783\n",
      "epoch 4/4, step 900/12500, loss = 0.8161\n",
      "epoch 4/4, step 1000/12500, loss = 2.1323\n",
      "epoch 4/4, step 1100/12500, loss = 2.0512\n",
      "epoch 4/4, step 1200/12500, loss = 1.9057\n",
      "epoch 4/4, step 1300/12500, loss = 1.9788\n",
      "epoch 4/4, step 1400/12500, loss = 1.4182\n",
      "epoch 4/4, step 1500/12500, loss = 1.8622\n",
      "epoch 4/4, step 1600/12500, loss = 1.3901\n",
      "epoch 4/4, step 1700/12500, loss = 1.9258\n",
      "epoch 4/4, step 1800/12500, loss = 1.5436\n",
      "epoch 4/4, step 1900/12500, loss = 1.2753\n",
      "epoch 4/4, step 2000/12500, loss = 1.8590\n",
      "epoch 4/4, step 2100/12500, loss = 2.6643\n",
      "epoch 4/4, step 2200/12500, loss = 1.1362\n",
      "epoch 4/4, step 2300/12500, loss = 1.3101\n",
      "epoch 4/4, step 2400/12500, loss = 1.7812\n",
      "epoch 4/4, step 2500/12500, loss = 1.7770\n",
      "epoch 4/4, step 2600/12500, loss = 1.2604\n",
      "epoch 4/4, step 2700/12500, loss = 1.9631\n",
      "epoch 4/4, step 2800/12500, loss = 1.6737\n",
      "epoch 4/4, step 2900/12500, loss = 1.7896\n",
      "epoch 4/4, step 3000/12500, loss = 1.3369\n",
      "epoch 4/4, step 3100/12500, loss = 1.2918\n",
      "epoch 4/4, step 3200/12500, loss = 1.2148\n",
      "epoch 4/4, step 3300/12500, loss = 2.8433\n",
      "epoch 4/4, step 3400/12500, loss = 2.0711\n",
      "epoch 4/4, step 3500/12500, loss = 2.0803\n",
      "epoch 4/4, step 3600/12500, loss = 2.3221\n",
      "epoch 4/4, step 3700/12500, loss = 1.4850\n",
      "epoch 4/4, step 3800/12500, loss = 1.4677\n",
      "epoch 4/4, step 3900/12500, loss = 2.6587\n",
      "epoch 4/4, step 4000/12500, loss = 1.0671\n",
      "epoch 4/4, step 4100/12500, loss = 1.3898\n",
      "epoch 4/4, step 4200/12500, loss = 0.6540\n",
      "epoch 4/4, step 4300/12500, loss = 1.4547\n",
      "epoch 4/4, step 4400/12500, loss = 1.2754\n",
      "epoch 4/4, step 4500/12500, loss = 1.6226\n",
      "epoch 4/4, step 4600/12500, loss = 1.9502\n",
      "epoch 4/4, step 4700/12500, loss = 1.3037\n",
      "epoch 4/4, step 4800/12500, loss = 0.7089\n",
      "epoch 4/4, step 4900/12500, loss = 1.8597\n",
      "epoch 4/4, step 5000/12500, loss = 1.9536\n",
      "epoch 4/4, step 5100/12500, loss = 1.5448\n",
      "epoch 4/4, step 5200/12500, loss = 1.6591\n",
      "epoch 4/4, step 5300/12500, loss = 1.6879\n",
      "epoch 4/4, step 5400/12500, loss = 1.1908\n",
      "epoch 4/4, step 5500/12500, loss = 0.9096\n",
      "epoch 4/4, step 5600/12500, loss = 1.1304\n",
      "epoch 4/4, step 5700/12500, loss = 1.4176\n",
      "epoch 4/4, step 5800/12500, loss = 1.3765\n",
      "epoch 4/4, step 5900/12500, loss = 1.0628\n",
      "epoch 4/4, step 6000/12500, loss = 0.9021\n",
      "epoch 4/4, step 6100/12500, loss = 1.0037\n",
      "epoch 4/4, step 6200/12500, loss = 1.5994\n",
      "epoch 4/4, step 6300/12500, loss = 1.0056\n",
      "epoch 4/4, step 6400/12500, loss = 1.6003\n",
      "epoch 4/4, step 6500/12500, loss = 1.6435\n",
      "epoch 4/4, step 6600/12500, loss = 1.1619\n",
      "epoch 4/4, step 6700/12500, loss = 1.4155\n",
      "epoch 4/4, step 6800/12500, loss = 1.6704\n",
      "epoch 4/4, step 6900/12500, loss = 0.8557\n",
      "epoch 4/4, step 7000/12500, loss = 1.4871\n",
      "epoch 4/4, step 7100/12500, loss = 1.5745\n",
      "epoch 4/4, step 7200/12500, loss = 2.1435\n",
      "epoch 4/4, step 7300/12500, loss = 1.2675\n",
      "epoch 4/4, step 7400/12500, loss = 1.7638\n",
      "epoch 4/4, step 7500/12500, loss = 1.1856\n",
      "epoch 4/4, step 7600/12500, loss = 2.0331\n",
      "epoch 4/4, step 7700/12500, loss = 2.2112\n",
      "epoch 4/4, step 7800/12500, loss = 2.8174\n",
      "epoch 4/4, step 7900/12500, loss = 1.5276\n",
      "epoch 4/4, step 8000/12500, loss = 1.4005\n",
      "epoch 4/4, step 8100/12500, loss = 1.3630\n",
      "epoch 4/4, step 8200/12500, loss = 0.5725\n",
      "epoch 4/4, step 8300/12500, loss = 1.6671\n",
      "epoch 4/4, step 8400/12500, loss = 1.3644\n",
      "epoch 4/4, step 8500/12500, loss = 1.6812\n",
      "epoch 4/4, step 8600/12500, loss = 1.2712\n",
      "epoch 4/4, step 8700/12500, loss = 1.0982\n",
      "epoch 4/4, step 8800/12500, loss = 0.9554\n",
      "epoch 4/4, step 8900/12500, loss = 1.4248\n",
      "epoch 4/4, step 9000/12500, loss = 1.0131\n",
      "epoch 4/4, step 9100/12500, loss = 2.0573\n",
      "epoch 4/4, step 9200/12500, loss = 2.6683\n",
      "epoch 4/4, step 9300/12500, loss = 0.7390\n",
      "epoch 4/4, step 9400/12500, loss = 2.5066\n",
      "epoch 4/4, step 9500/12500, loss = 0.6475\n",
      "epoch 4/4, step 9600/12500, loss = 1.2226\n",
      "epoch 4/4, step 9700/12500, loss = 1.7191\n",
      "epoch 4/4, step 9800/12500, loss = 1.9447\n",
      "epoch 4/4, step 9900/12500, loss = 1.9007\n",
      "epoch 4/4, step 10000/12500, loss = 1.6949\n",
      "epoch 4/4, step 10100/12500, loss = 1.1270\n",
      "epoch 4/4, step 10200/12500, loss = 1.3425\n",
      "epoch 4/4, step 10300/12500, loss = 2.1036\n",
      "epoch 4/4, step 10400/12500, loss = 1.2053\n",
      "epoch 4/4, step 10500/12500, loss = 1.2825\n",
      "epoch 4/4, step 10600/12500, loss = 1.9448\n",
      "epoch 4/4, step 10700/12500, loss = 1.5115\n",
      "epoch 4/4, step 10800/12500, loss = 1.6807\n",
      "epoch 4/4, step 10900/12500, loss = 1.5832\n",
      "epoch 4/4, step 11000/12500, loss = 1.8772\n",
      "epoch 4/4, step 11100/12500, loss = 1.3565\n",
      "epoch 4/4, step 11200/12500, loss = 1.2942\n",
      "epoch 4/4, step 11300/12500, loss = 1.6626\n",
      "epoch 4/4, step 11400/12500, loss = 0.7412\n",
      "epoch 4/4, step 11500/12500, loss = 1.0106\n",
      "epoch 4/4, step 11600/12500, loss = 1.3620\n",
      "epoch 4/4, step 11700/12500, loss = 1.4450\n",
      "epoch 4/4, step 11800/12500, loss = 2.0240\n",
      "epoch 4/4, step 11900/12500, loss = 1.7612\n",
      "epoch 4/4, step 12000/12500, loss = 1.6397\n",
      "epoch 4/4, step 12100/12500, loss = 1.0047\n",
      "epoch 4/4, step 12200/12500, loss = 0.8528\n",
      "epoch 4/4, step 12300/12500, loss = 0.6962\n",
      "epoch 4/4, step 12400/12500, loss = 1.3311\n",
      "epoch 4/4, step 12500/12500, loss = 1.2768\n",
      "Finished Training\n",
      "Accuracy of the network: 47.32 %\n",
      "Accuracy of the plane: 48.2 %\n",
      "Accuracy of the car: 71.5 %\n",
      "Accuracy of the bird: 23.8 %\n",
      "Accuracy of the cat: 36.7 %\n",
      "Accuracy of the deer: 31.9 %\n",
      "Accuracy of the dog: 44.8 %\n",
      "Accuracy of the frog: 62.2 %\n",
      "Accuracy of the horse: 52.6 %\n",
      "Accuracy of the ship: 64.3 %\n",
      "Accuracy of the truck: 37.2 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#implement conv net \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 =nn.Conv2d(3,6,5)\n",
    "        self.pool =nn.MaxPool2d(2,2)\n",
    "        self.conv2 =nn.Conv2d(6,16,5)\n",
    "        self.fc1 =nn.Linear(16*5*5,120)\n",
    "        self.fc2 =nn.Linear(120,84)\n",
    "        self.fc3 =nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader) :\n",
    "        # original shape: [4, 3, 32 ,32] =4,3,1024\n",
    "        # input_layer : 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # Backward and optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0 :\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_corrent = 0 \n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # Max returns (value, index)\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_corrent += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred) :\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] +=1\n",
    "        \n",
    "    acc =100.0 * n_corrent / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of the {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8 (tags/v3.9.8:bb3fdcf, Nov  5 2021, 20:48:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14958d3aee5f1cad06795f787e54b96185c25fb40dfec723a5be941f3a531b8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
